{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ba842c",
   "metadata": {
    "papermill": {
     "duration": 0.009173,
     "end_time": "2023-03-22T07:55:10.299174",
     "exception": false,
     "start_time": "2023-03-22T07:55:10.290001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dd7eb5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.025921,
     "end_time": "2023-03-22T07:55:10.333397",
     "exception": false,
     "start_time": "2023-03-22T07:55:10.307476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import itertools\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, log_loss, roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import torch\n",
    "from deepctr_torch.models import DeepFM,DCN\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1246d02-b44e-4820-8fb0-23307964b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440e32f",
   "metadata": {
    "papermill": {
     "duration": 0.008018,
     "end_time": "2023-03-22T07:55:10.349400",
     "exception": false,
     "start_time": "2023-03-22T07:55:10.341382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0237e9",
   "metadata": {
    "papermill": {
     "duration": 138.578101,
     "end_time": "2023-03-22T07:58:08.787943",
     "exception": false,
     "start_time": "2023-03-22T07:55:50.209842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv(\"./data/my_train.csv\", header=0, dtype=str)\n",
    "test_df = pd.read_csv(\"./data/my_test.csv\", header=0, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9582eae-f94e-44af-998f-7c0ffd62db29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870e3e3a",
   "metadata": {
    "papermill": {
     "duration": 0.054681,
     "end_time": "2023-03-22T07:58:26.997010",
     "exception": false,
     "start_time": "2023-03-22T07:58:26.942329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['data_label'] = 'test'\n",
    "train['data_label'] = 'train'\n",
    "train_test = pd.concat([test_df,train])\n",
    "data1 = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad73a0b",
   "metadata": {
    "papermill": {
     "duration": 44.5609,
     "end_time": "2023-03-22T07:59:13.443673",
     "exception": false,
     "start_time": "2023-03-22T07:58:28.882773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1['hour'] = pd.to_datetime(data1['hour'], format = '%y%m%d%H')\n",
    "data1['click'] = pd.to_numeric(data1['click'], errors='coerce')\n",
    "data1['dt'] = data1['hour'].apply(lambda x:str(x)[:10])\n",
    "device_id_sum = data1.groupby(['dt','device_id']).click.sum().reset_index(name='id_sum')\n",
    "device_id_cnt = data1.groupby(['dt','device_id']).click.count().reset_index(name='id_cnt')\n",
    "cnt_sum = pd.merge(device_id_cnt,device_id_sum,on=(['dt','device_id']),how='left')\n",
    "cnt_sum['device_ctr'] = cnt_sum['id_sum']/cnt_sum['id_cnt']\n",
    "cnt_sum = cnt_sum.sort_values(['device_id','dt'])\n",
    "cnt_sum['device_ctr'] = cnt_sum['id_sum']/cnt_sum['id_cnt']\n",
    "cnt_sum = cnt_sum.sort_values(['device_id','dt'])\n",
    "cnt_sum['t_1']=cnt_sum.groupby(['device_id'])['device_ctr'].shift(1)\n",
    "cnt_sum.groupby('device_id')['dt'].count().reset_index().sort_values('dt',ascending=False)\n",
    "data2 = pd.merge(data1,cnt_sum,on=(['dt','device_id']),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c621c7",
   "metadata": {
    "papermill": {
     "duration": 0.021767,
     "end_time": "2023-03-22T07:59:13.631952",
     "exception": false,
     "start_time": "2023-03-22T07:59:13.610185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3041c025",
   "metadata": {
    "papermill": {
     "duration": 0.91064,
     "end_time": "2023-03-22T07:59:14.555161",
     "exception": false,
     "start_time": "2023-03-22T07:59:13.644521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1['hour_of_day'] = data1['hour'].dt.hour\n",
    "data1['weekday'] = (data1['hour'].dt.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030c9dc5",
   "metadata": {
    "papermill": {
     "duration": 0.022179,
     "end_time": "2023-03-22T07:59:14.589933",
     "exception": false,
     "start_time": "2023-03-22T07:59:14.567754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj_cols = ['site_id',\n",
    " 'site_domain',\n",
    " 'site_category',\n",
    " 'app_id',\n",
    " 'app_domain',\n",
    " 'app_category',\n",
    " 'device_id',\n",
    " 'device_ip',\n",
    " 'device_model','device_type','device_conn_type'\n",
    ",'hour_of_day','weekday','banner_pos']\n",
    "c_cols = ['C14',\n",
    " 'C15',\n",
    " 'C16',\n",
    " 'C17',\n",
    " 'C18',\n",
    " 'C19',\n",
    " 'C20',\n",
    " 'C21','C1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573b6d0e",
   "metadata": {
    "papermill": {
     "duration": 0.024879,
     "end_time": "2023-03-22T07:59:14.627499",
     "exception": false,
     "start_time": "2023-03-22T07:59:14.602620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sparse特征列\n",
    "sparse_features = obj_cols+['hour_of_day','weekday']+ c_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41471caa",
   "metadata": {
    "papermill": {
     "duration": 2.628958,
     "end_time": "2023-03-22T07:59:17.269712",
     "exception": false,
     "start_time": "2023-03-22T07:59:14.640754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Padding\n",
    "for f in ['device_type','device_conn_type','banner_pos'\n",
    "          ,'C14','C15','C16','C17','C18', 'C19', 'C20', 'C21', 'C1']:\n",
    "    data1[f] = data1[f].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d02e1c48",
   "metadata": {
    "papermill": {
     "duration": 6.259701,
     "end_time": "2023-03-22T07:59:23.541959",
     "exception": false,
     "start_time": "2023-03-22T07:59:17.282258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in sparse_features:\n",
    "    data1[f] = data1[f].fillna('-1', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435b1cbc",
   "metadata": {
    "papermill": {
     "duration": 60.684213,
     "end_time": "2023-03-22T08:00:24.239253",
     "exception": false,
     "start_time": "2023-03-22T07:59:23.555040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对sparse onehot\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data1[feat] = lbe.fit_transform(data1[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67889183",
   "metadata": {
    "papermill": {
     "duration": 1.985727,
     "end_time": "2023-03-22T08:00:26.293421",
     "exception": false,
     "start_time": "2023-03-22T08:00:24.307694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continuous Features\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "dense_features = ['id_cnt',\n",
    " 'id_sum',\n",
    " 'device_ctr',\n",
    " 't_1']\n",
    "for f in dense_features:\n",
    "    data1[f] = data1[f].fillna(0, )\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data1[dense_features] = mms.fit_transform(data1[dense_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a091ade4",
   "metadata": {
    "papermill": {
     "duration": 0.751312,
     "end_time": "2023-03-22T08:00:27.058908",
     "exception": false,
     "start_time": "2023-03-22T08:00:26.307596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data1[feat].nunique(),embedding_dim=4 )\n",
    "                       for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                      for feat in dense_features]\n",
    "# fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data1[feat].nunique(),embedding_dim=4 )\n",
    "#                        for i,feat in enumerate(sparse_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "936d8427",
   "metadata": {
    "papermill": {
     "duration": 0.025897,
     "end_time": "2023-03-22T08:00:27.099369",
     "exception": false,
     "start_time": "2023-03-22T08:00:27.073472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a093df44",
   "metadata": {
    "papermill": {
     "duration": 1.56763,
     "end_time": "2023-03-22T08:00:28.886951",
     "exception": false,
     "start_time": "2023-03-22T08:00:27.319321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data1[data1['data_label']=='train']\n",
    "train_1 = train[:27000]\n",
    "train_2 = train[30000:360000]\n",
    "test_old = data1[data1['data_label']=='test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac6bb39-d3b3-4b3c-8507-c15b5d41c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = train[27000:30000]\n",
    "test_1_model_input = {name:test_1[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3029e032",
   "metadata": {
    "papermill": {
     "duration": 0.029333,
     "end_time": "2023-03-22T08:00:29.279344",
     "exception": false,
     "start_time": "2023-03-22T08:00:29.250011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_1_model_input = {name:train_1[name] for name in feature_names}\n",
    "train_2_model_input = {name:train_2[name] for name in feature_names}\n",
    "\n",
    "test_model_input = {name:test_old[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde6bba6-e74a-4986-afb8-014da0831645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Binary Cross-Entropy Loss.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True binary labels (shape: [n_samples]).\n",
    "        y_pred (numpy.ndarray): Predicted probabilities (shape: [n_samples]).\n",
    "\n",
    "    Returns:\n",
    "        float: Binary Cross-Entropy loss.\n",
    "    \"\"\"\n",
    "    # Clip predictions to avoid log(0)\n",
    "    y_pred = np.clip(y_pred, 1e-12, 1. - 1e-12)\n",
    "    # Compute BCE\n",
    "    bce = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return bce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33f071b9",
   "metadata": {
    "papermill": {
     "duration": 0.030655,
     "end_time": "2023-03-22T08:00:29.324801",
     "exception": false,
     "start_time": "2023-03-22T08:00:29.294146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DeepFM,AFM,xDeepFM,AutoInt,DCN,DIFM\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75add29e-bf24-4768-af9c-a2a79fd868da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 24300 samples, validate on 2700 samples, 190 steps per epoch\n",
      "Epoch 1/1\n",
      "5s - loss:  0.4312 - binary_crossentropy:  0.4312 - val_binary_crossentropy:  0.4038\n"
     ]
    }
   ],
   "source": [
    "model = DCN(linear_feature_columns,dnn_feature_columns,task='binary',device=device)\n",
    "model.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model.fit(train_1_model_input,train_1['click'].values,batch_size=128,epochs=1,verbose=2,validation_split=0.1)\n",
    "train_2['pred']= model.predict(train_2_model_input, batch_size=128)\n",
    "collected_train = train_2.groupby(train_2.index // 10).apply(lambda x: x.loc[x[\"pred\"].idxmax()])\n",
    "test_old['pred_1']= model.predict(test_model_input, batch_size=128)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce50a43-45e8-42d5-ba69-970e0f67743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 24300 samples, validate on 2700 samples, 190 steps per epoch\n",
      "Epoch 1/1\n",
      "5s - loss:  0.4268 - binary_crossentropy:  0.4267 - val_binary_crossentropy:  0.3968\n"
     ]
    }
   ],
   "source": [
    "model_best = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary',device=device)\n",
    "model_best.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model_best.fit(train_1_model_input,train_1['click'].values,batch_size=128,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_best']= model_best.predict(test_model_input, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79215a9b-894e-498d-8214-33e1a9ed9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = collected_train[:3000]\n",
    "validation_model_input = {name:validation[name] for name in feature_names}\n",
    "new_train=collected_train[3000:]\n",
    "new_train_model_input = {name:new_train[name] for name in feature_names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81ab1b8a-bece-4587-98e9-09fce85598dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_train['click'].to_csv(\"offline_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5abf970-d3c6-4f8b-a12f-3ed820d870bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 27000 samples, validate on 3000 samples, 422 steps per epoch\n",
      "Epoch 1/1\n",
      "12s - loss:  0.5953 - binary_crossentropy:  0.5953 - val_binary_crossentropy:  0.5768\n",
      "cpu\n",
      "Train on 27000 samples, validate on 3000 samples, 422 steps per epoch\n",
      "Epoch 1/1\n",
      "10s - loss:  0.5909 - binary_crossentropy:  0.5909 - val_binary_crossentropy:  0.5671\n",
      "cpu\n",
      "Train on 27000 samples, validate on 3000 samples, 422 steps per epoch\n",
      "Epoch 1/1\n",
      "10s - loss:  0.5952 - binary_crossentropy:  0.5951 - val_binary_crossentropy:  0.5777\n",
      "cpu\n",
      "Train on 27000 samples, validate on 3000 samples, 422 steps per epoch\n",
      "Epoch 1/1\n",
      "10s - loss:  0.5969 - binary_crossentropy:  0.5968 - val_binary_crossentropy:  0.5768\n",
      "cpu\n",
      "Train on 27000 samples, validate on 3000 samples, 422 steps per epoch\n",
      "Epoch 1/1\n",
      "9s - loss:  0.5936 - binary_crossentropy:  0.5936 - val_binary_crossentropy:  0.5702\n",
      "cpu\n",
      "Train on 27000 samples, validate on 3000 samples, 422 steps per epoch\n",
      "Epoch 1/1\n",
      "10s - loss:  0.5965 - binary_crossentropy:  0.5965 - val_binary_crossentropy:  0.5832\n"
     ]
    }
   ],
   "source": [
    "model2 = DIFM(linear_feature_columns,dnn_feature_columns,task='binary',device=device)\n",
    "model2.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model2.fit(new_train_model_input,new_train['click'].values,batch_size=64,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_2']= model2.predict(test_model_input, batch_size=128)\n",
    "\n",
    "model3 = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary',device=device)\n",
    "model3.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model3.fit(new_train_model_input,new_train['click'].values,batch_size=64,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_3']= model3.predict(test_model_input, batch_size=128)\n",
    "\n",
    "model4 = DCN(linear_feature_columns,dnn_feature_columns,task='binary',device=device)\n",
    "model4.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model4.fit(new_train_model_input,new_train['click'].values,batch_size=64,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_4']= model4.predict(test_model_input, batch_size=128)\n",
    "\n",
    "model5 = DIFM(linear_feature_columns,dnn_feature_columns,task='binary',device=device, dnn_hidden_units=(256, 128, 64),)\n",
    "model5.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model5.fit(new_train_model_input,new_train['click'].values,batch_size=64,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_5']= model5.predict(test_model_input, batch_size=128)\n",
    "\n",
    "model6 = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary',device=device, dnn_hidden_units=(128, 128, 64))\n",
    "model6.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model6.fit(new_train_model_input,new_train['click'].values,batch_size=64,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_6']= model6.predict(test_model_input, batch_size=128)\n",
    "\n",
    "model7 = DCN(linear_feature_columns,dnn_feature_columns,task='binary',device=device, dnn_hidden_units=(256, 128, 64),)\n",
    "model7.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "history = model7.fit(new_train_model_input,new_train['click'].values,batch_size=64,epochs=1,verbose=2,validation_split=0.1)\n",
    "test_old['pred_7']= model7.predict(test_model_input, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "983b62d8-b9de-4b99-981c-a94c42f92e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define Binary Cross-Entropy loss function\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "605ff31b-bbda-496c-a69e-85e201c10a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_1 , binary cross entropy loss:  0.39470598101615906\n",
      "pred_2 , binary cross entropy loss:  0.8969165682792664\n",
      "pred_3 , binary cross entropy loss:  0.6406513452529907\n",
      "pred_4 , binary cross entropy loss:  0.7149401307106018\n",
      "pred_5 , binary cross entropy loss:  1.0635292530059814\n",
      "pred_6 , binary cross entropy loss:  0.6902387738227844\n",
      "pred_7 , binary cross entropy loss:  0.7526766657829285\n",
      "pred_best , binary cross entropy loss:  0.3880247473716736\n"
     ]
    }
   ],
   "source": [
    "test_1[\"pred_1\"]= model.predict(test_1_model_input, batch_size=128)\n",
    "test_1[\"pred_2\"]= model2.predict(test_1_model_input, batch_size=128)\n",
    "test_1[\"pred_3\"]= model3.predict(test_1_model_input, batch_size=128)\n",
    "test_1[\"pred_4\"]= model4.predict(test_1_model_input, batch_size=128)\n",
    "test_1[\"pred_5\"]= model5.predict(test_1_model_input, batch_size=128)\n",
    "test_1[\"pred_6\"]= model6.predict(test_1_model_input, batch_size=128)\n",
    "test_1[\"pred_7\"]= model7.predict(test_1_model_input, batch_size=128)\n",
    "\n",
    "test_1[\"pred_best\"]= model_best.predict(test_1_model_input, batch_size=128)\n",
    "\n",
    "for num_model in [\"pred_1\",\"pred_2\",\"pred_3\",\"pred_4\",\"pred_5\",\"pred_6\",\"pred_7\",\"pred_best\"]:\n",
    "    print(num_model, \", binary cross entropy loss: \", criterion(torch.tensor(test_1[num_model].values, dtype=torch.float32)\n",
    "                                                                ,torch.tensor(test_1[\"click\"].values, dtype=torch.float32)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ce800d9-fe09-4253-a9ce-a147ad8581b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_1 , binary cross entropy loss:  0.6664384603500366\n",
      "pred_2 , binary cross entropy loss:  0.5767185688018799\n",
      "pred_3 , binary cross entropy loss:  0.5668131709098816\n",
      "pred_4 , binary cross entropy loss:  0.5762074589729309\n",
      "pred_5 , binary cross entropy loss:  0.5760177969932556\n",
      "pred_6 , binary cross entropy loss:  0.5721731185913086\n",
      "pred_7 , binary cross entropy loss:  0.5796493291854858\n",
      "pred_best , binary cross entropy loss:  0.6481015682220459\n"
     ]
    }
   ],
   "source": [
    "validation[\"pred_1\"]= model.predict(validation_model_input, batch_size=128)\n",
    "validation[\"pred_2\"]= model2.predict(validation_model_input, batch_size=128)\n",
    "validation[\"pred_3\"]= model3.predict(validation_model_input, batch_size=128)\n",
    "validation[\"pred_4\"]= model4.predict(validation_model_input, batch_size=128)\n",
    "validation[\"pred_5\"]= model5.predict(validation_model_input, batch_size=128)\n",
    "validation[\"pred_6\"]= model6.predict(validation_model_input, batch_size=128)\n",
    "validation[\"pred_7\"]= model7.predict(validation_model_input, batch_size=128)\n",
    "\n",
    "validation[\"pred_best\"]= model_best.predict(validation_model_input, batch_size=128)\n",
    "\n",
    "for num_model in [\"pred_1\",\"pred_2\",\"pred_3\",\"pred_4\",\"pred_5\",\"pred_6\",\"pred_7\",\"pred_best\"]:\n",
    "    print(num_model, \", binary cross entropy loss: \", criterion(torch.tensor(validation[num_model].values, dtype=torch.float32)\n",
    "                                                                ,torch.tensor(validation[\"click\"].values, dtype=torch.float32)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48c501d7-c0e9-44c0-95f3-528199cffb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward_table(test_old):\n",
    "    reward1 = test_old.groupby(test_old.index // 10).apply(lambda x: x.loc[x[\"pred_1\"].idxmax()])\n",
    "    for num_model in [\"pred_2\",\"pred_3\",\"pred_4\",\"pred_5\",\"pred_6\",\"pred_7\",\"pred_best\"]:\n",
    "        reward1[num_model] = test_old.groupby(test_old.index // 10).apply(lambda x: x.loc[x[num_model].idxmax()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6395b-3222-4b7e-b4b9-3190ea73c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward1 = test_old.groupby(test_old.index // 10).apply(lambda x: x.loc[x[\"pred_1\"].idxmax()])[[\"click\"]]\n",
    "for num_model in [\"pred_2\",\"pred_3\",\"pred_4\",\"pred_5\",\"pred_6\",\"pred_7\",\"pred_best\"]:\n",
    "    rw =test_old.groupby(test_old.index // 10).apply(lambda x: x.loc[x[num_model].idxmax()])[[\"click\"]]\n",
    "    reward1[num_model] = rw[\"click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb0fce-612a-4c09-a563-9af88074c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward1.rename(columns={'click': 'pred_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1425aeb8-1939-4b88-8325-b18d9477db0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_1       0.429330\n",
       "pred_2       0.167433\n",
       "pred_3       0.260790\n",
       "pred_4       0.255587\n",
       "pred_5       0.165907\n",
       "pred_6       0.242280\n",
       "pred_7       0.249797\n",
       "pred_best    0.451547\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reward1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7f32e-e651-47a3-906c-12384c9c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward1.to_csv(\"reward_table_bis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea7de217-21d8-4de6-89bb-ff340e4fea2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reward1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a41ae88-5f62-4f17-bb24-52d0b5dda5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4306969696969697"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(collected_train['click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7a1a9-4e81-4c3e-a777-afa950f09400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 546.877315,
   "end_time": "2023-03-22T08:04:07.325930",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-22T07:55:00.448615",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
